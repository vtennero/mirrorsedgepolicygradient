{
    "name": "root",
    "gauges": {
        "ParkourRunner.Policy.Entropy.mean": {
            "value": 0.11595964431762695,
            "min": 0.11241066455841064,
            "max": 1.0943727493286133,
            "count": 100
        },
        "ParkourRunner.Policy.Entropy.sum": {
            "value": 2316.2939453125,
            "min": 2254.836669921875,
            "max": 22362.412109375,
            "count": 100
        },
        "ParkourRunner.Environment.EpisodeLength.mean": {
            "value": 86.97835497835497,
            "min": 49.285714285714285,
            "max": 87.25,
            "count": 100
        },
        "ParkourRunner.Environment.EpisodeLength.sum": {
            "value": 20092.0,
            "min": 19176.0,
            "max": 20469.0,
            "count": 100
        },
        "ParkourRunner.Episode.TotalReward.mean": {
            "value": 3.4017412739914734,
            "min": -0.12066674201438825,
            "max": 3.4017412739914734,
            "count": 100
        },
        "ParkourRunner.Episode.TotalReward.sum": {
            "value": 785.8022342920303,
            "min": -46.336028933525085,
            "max": 785.8022342920303,
            "count": 100
        },
        "ParkourRunner.Episode.Length.mean": {
            "value": 8.79815099559305,
            "min": 5.028738415971095,
            "max": 8.82550037639183,
            "count": 100
        },
        "ParkourRunner.Episode.Length.sum": {
            "value": 2032.3728799819946,
            "min": 1941.8522906303406,
            "max": 2072.851126432419,
            "count": 100
        },
        "ParkourRunner.Episode.MaxDistance.mean": {
            "value": 48.01334281607624,
            "min": 11.105859032521645,
            "max": 48.01334281607624,
            "count": 100
        },
        "ParkourRunner.Episode.MaxDistance.sum": {
            "value": 11091.08219051361,
            "min": 4264.649868488312,
            "max": 11321.401689529419,
            "count": 100
        },
        "ParkourRunner.Actions.JumpCount.mean": {
            "value": 31.138528138528137,
            "min": 24.424460431654676,
            "max": 82.44791666666667,
            "count": 100
        },
        "ParkourRunner.Actions.JumpCount.sum": {
            "value": 7193.0,
            "min": 6406.0,
            "max": 31660.0,
            "count": 100
        },
        "ParkourRunner.Actions.ForwardCount.mean": {
            "value": 401.995670995671,
            "min": 92.76041666666667,
            "max": 401.995670995671,
            "count": 100
        },
        "ParkourRunner.Actions.ForwardCount.sum": {
            "value": 92861.0,
            "min": 35620.0,
            "max": 94595.0,
            "count": 100
        },
        "ParkourRunner.Actions.IdleCount.mean": {
            "value": 6.770562770562771,
            "min": 6.354330708661418,
            "max": 83.46354166666667,
            "count": 100
        },
        "ParkourRunner.Actions.IdleCount.sum": {
            "value": 1564.0,
            "min": 1564.0,
            "max": 32050.0,
            "count": 100
        },
        "ParkourRunner.Actions.JumpPercentage.mean": {
            "value": 6.256664290572658,
            "min": 5.609504578559379,
            "max": 31.162290260195732,
            "count": 100
        },
        "ParkourRunner.Actions.JumpPercentage.sum": {
            "value": 1445.289451122284,
            "min": 1379.9381263256073,
            "max": 11966.319459915161,
            "count": 100
        },
        "ParkourRunner.Actions.ForwardPercentage.mean": {
            "value": 91.40459419019294,
            "min": 37.22186324993769,
            "max": 91.67505988296197,
            "count": 100
        },
        "ParkourRunner.Actions.ForwardPercentage.sum": {
            "value": 21114.46125793457,
            "min": 14293.195487976074,
            "max": 26617.710243225098,
            "count": 100
        },
        "ParkourRunner.Actions.IdlePercentage.mean": {
            "value": 2.3387412795256743,
            "min": 2.132175142646801,
            "max": 31.615846417844296,
            "count": 100
        },
        "ParkourRunner.Actions.IdlePercentage.sum": {
            "value": 540.2492355704308,
            "min": 526.6472602337599,
            "max": 12140.48502445221,
            "count": 100
        },
        "ParkourRunner.Step.mean": {
            "value": 1999988.0,
            "min": 19968.0,
            "max": 1999988.0,
            "count": 100
        },
        "ParkourRunner.Step.sum": {
            "value": 1999988.0,
            "min": 19968.0,
            "max": 1999988.0,
            "count": 100
        },
        "ParkourRunner.Policy.ExtrinsicValueEstimate.mean": {
            "value": 1.257095456123352,
            "min": -0.19041508436203003,
            "max": 1.3491945266723633,
            "count": 100
        },
        "ParkourRunner.Policy.ExtrinsicValueEstimate.sum": {
            "value": 348.2154541015625,
            "min": -77.87976837158203,
            "max": 411.1443176269531,
            "count": 100
        },
        "ParkourRunner.Environment.CumulativeReward.mean": {
            "value": 3.4262814537204545,
            "min": -0.12199212910301069,
            "max": 3.4262814537204545,
            "count": 100
        },
        "ParkourRunner.Environment.CumulativeReward.sum": {
            "value": 794.8972972631454,
            "min": -46.722985446453094,
            "max": 794.8972972631454,
            "count": 100
        },
        "ParkourRunner.Policy.ExtrinsicReward.mean": {
            "value": 3.4262814537204545,
            "min": -0.12199212910301069,
            "max": 3.4262814537204545,
            "count": 100
        },
        "ParkourRunner.Policy.ExtrinsicReward.sum": {
            "value": 794.8972972631454,
            "min": -46.722985446453094,
            "max": 794.8972972631454,
            "count": 100
        },
        "ParkourRunner.Losses.PolicyLoss.mean": {
            "value": 0.020694386530667543,
            "min": 0.018944261781871318,
            "max": 0.02944073823746294,
            "count": 100
        },
        "ParkourRunner.Losses.PolicyLoss.sum": {
            "value": 0.04138877306133509,
            "min": 0.01977189738303423,
            "max": 0.05888147647492588,
            "count": 100
        },
        "ParkourRunner.Losses.ValueLoss.mean": {
            "value": 0.44691891193389893,
            "min": 0.07112546764314175,
            "max": 0.5184628254175185,
            "count": 100
        },
        "ParkourRunner.Losses.ValueLoss.sum": {
            "value": 0.8938378238677979,
            "min": 0.07112546764314175,
            "max": 1.036925650835037,
            "count": 100
        },
        "ParkourRunner.Policy.LearningRate.mean": {
            "value": 1.4925245025249915e-06,
            "min": 1.4925245025249915e-06,
            "max": 0.0002984622005126,
            "count": 100
        },
        "ParkourRunner.Policy.LearningRate.sum": {
            "value": 2.985049005049983e-06,
            "min": 2.985049005049983e-06,
            "max": 0.00059231295256235,
            "count": 100
        },
        "ParkourRunner.Policy.Epsilon.mean": {
            "value": 0.100497475,
            "min": 0.100497475,
            "max": 0.19948740000000004,
            "count": 100
        },
        "ParkourRunner.Policy.Epsilon.sum": {
            "value": 0.20099495,
            "min": 0.1094951,
            "max": 0.3974376500000001,
            "count": 100
        },
        "ParkourRunner.Policy.Beta.mean": {
            "value": 8.457150249999959e-05,
            "min": 8.457150249999959e-05,
            "max": 0.014923161260000001,
            "count": 100
        },
        "ParkourRunner.Policy.Beta.sum": {
            "value": 0.00016914300499999918,
            "min": 0.00016914300499999918,
            "max": 0.029615903734999997,
            "count": 100
        },
        "ParkourRunner.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 100
        },
        "ParkourRunner.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 100
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1764369303",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\victo\\.conda\\envs\\mlagents\\Scripts\\mlagents-learn parkour_config.yaml --run-id=test_v9 --time-scale=50 --force",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.2.2+cu121",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1764372637"
    },
    "total": 3333.955704299995,
    "count": 1,
    "self": 0.007012300004134886,
    "children": {
        "run_training.setup": {
            "total": 0.06406189998961054,
            "count": 1,
            "self": 0.06406189998961054
        },
        "TrainerController.start_learning": {
            "total": 3333.8846301000012,
            "count": 1,
            "self": 2.6768040020397166,
            "children": {
                "TrainerController._reset_env": {
                    "total": 10.917093600000953,
                    "count": 1,
                    "self": 10.917093600000953
                },
                "TrainerController.advance": {
                    "total": 3320.2276036979747,
                    "count": 141083,
                    "self": 2.448570399254095,
                    "children": {
                        "env_step": {
                            "total": 2076.151476600571,
                            "count": 141083,
                            "self": 620.2052977985877,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 1454.2957630018936,
                                    "count": 141083,
                                    "self": 6.990227499656612,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 1447.305535502237,
                                            "count": 117691,
                                            "self": 1447.305535502237
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 1.6504158000898315,
                                    "count": 141083,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 3320.7311421013146,
                                            "count": 141083,
                                            "is_parallel": true,
                                            "self": 2873.946971302619,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00042979999852832407,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00021869999181944877,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0002111000067088753,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.0002111000067088753
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 446.7837409986969,
                                                    "count": 141083,
                                                    "is_parallel": true,
                                                    "self": 15.614184996200493,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 26.102198299966403,
                                                            "count": 141083,
                                                            "is_parallel": true,
                                                            "self": 26.102198299966403
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 368.7546896026179,
                                                            "count": 141083,
                                                            "is_parallel": true,
                                                            "self": 368.7546896026179
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 36.312668099912116,
                                                            "count": 141083,
                                                            "is_parallel": true,
                                                            "self": 18.607562698802212,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 17.705105401109904,
                                                                    "count": 282166,
                                                                    "is_parallel": true,
                                                                    "self": 17.705105401109904
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 1241.6275566981494,
                            "count": 141083,
                            "self": 4.687185196540668,
                            "children": {
                                "process_trajectory": {
                                    "total": 383.3993223016005,
                                    "count": 141083,
                                    "self": 383.1631564015843,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.23616590001620352,
                                            "count": 4,
                                            "self": 0.23616590001620352
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 853.5410492000083,
                                    "count": 194,
                                    "self": 374.48130370042054,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 479.05974549958773,
                                            "count": 9700,
                                            "self": 479.05974549958773
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 5.999900167807937e-07,
                    "count": 1,
                    "self": 5.999900167807937e-07
                },
                "TrainerController._save_models": {
                    "total": 0.06312819999584462,
                    "count": 1,
                    "self": 0.016746900000725873,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.04638129999511875,
                            "count": 1,
                            "self": 0.04638129999511875
                        }
                    }
                }
            }
        }
    }
}